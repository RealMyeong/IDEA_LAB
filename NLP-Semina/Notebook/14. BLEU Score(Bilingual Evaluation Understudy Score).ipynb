{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Score(Bilingual Evaluation Understudy Score)\n",
    "\n",
    "앞서 언어 모델의 성능 측정을 위한 평가 방법으로 Perplexity(PPL)를 배운적이 있습니다. 기계 번역기에도 PPL을 평가에 사용할 수는 있지만, PPL은 번역의 성능을 직접적으로 반영하는 수치라 보기엔 어렵습니다.\n",
    "\n",
    "자연어 처리에서는 그 외에도 수많은 평가 방법들이 존재하는데, 기계 번역의 성능이 얼마나 뛰어난가를 측정하기 위해 사용되는 대표적인 방법인 BLEU(Bilingual Evaluation Understury)에 대해서 학습해보겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BLEU(Bilingual Evaluation Understudy)\n",
    "\n",
    "BLEU는 기계 번역 결과와 사람이 직접 번역한 결과가 얼마나 유사한지 비교하여 번역에 대한 성능을 측정하는 방법입니다. 측정 기준은 n-gram에 기반합니다.\n",
    "\n",
    "BLEU는 언어에 구애받지 않고 사용할 수 있으며, 계산 속도가 빠르다는 장점이 있습니다. BLEU는 PPL과 달리 높을 수록 성능이 더 좋음을 의미합니다. \n",
    "<br />\n",
    "\n",
    "### 1) 단어 개수 카운트로 측정하기(Unigram Precision)\n",
    "\n",
    "한국어-영어 번역기의 성능을 측정한다고 가정해봅시다. 두 개의 기계 번역기가 존재하고 두 기계 번역기에 같은 한국어 문장을 입력하여 번역된 영어 문장의 성능을 측정하고자 합니다.\n",
    "\n",
    "번역된 문장을 각각 Candidate 1, 2라고 해봅시다. 이 문장의 성능을 평가하기 위해서는 정답으로 비교되는 문장이 있어야 합니다.\n",
    "\n",
    "세 명의 사람에게 한국어를 보고 영작해보라고 하여 세 개의 번역 문장을 만들어냈습니다. 이 세 문장을 각각 Reference 1, 2, 3이라고 해보겠습니다.\n",
    "<br />\n",
    "<br />\n",
    "- Candidate1 : It is a guide to action which ensures that the military always obeys the commands of the party.\n",
    "\n",
    "- Candidate2 : It is to insure the troops forever hearing the activity guidebook that party direct.\n",
    "\n",
    "- Reference1 : It is a guide to action that ensures that the military will forever heed Party commands.\n",
    "\n",
    "- Reference2 : It is the guiding principle which guarantees the military forces always being under the command of the Party.\n",
    "\n",
    "- Reference3 : It is the practical guide for the army always to heed the directions of the party.\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "편의상 Candidate를 Ca로, Reference를 Ref로 축약하여 부르겠습니다.\n",
    "\n",
    "가장 직관적인 성능 평가 방법은 Ref 1, 2, 3중 어느 한 문장이라도 등장한 단어의 개수를 Ca에서 세는 것입니다. 그리고 그 후에 Ca의 모든 단어의 카운트의 합. 즉, Ca에서의 총 단어의 수로 나눠줍니다.\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "$$\\text{Unigram Precision} = \\frac{\\text{Ref들 중에서 존재하는 Ca의 단어의 수}}{{\\text{Ca의 총 단어의 수}}}$$\n",
    "<br />\n",
    "<br />\n",
    "Ca1의 단어들은 얼추 훑어만 봐도 Ref 1, 2, 3에 전반적으로 등장하는 반면, Ca2는 그렇지 않습니다. 이는 Ca1이 Ca2보다 더 좋은 번역 문장임을 의미합니다.<br /><br />\n",
    "위의 계산 방법에 따르면 Ca1과 Ca2의 유니그램 정밀도는 각각 아래와 같습니다.<br /><br />\n",
    "\n",
    "$$\\begin{aligned} \\text{Ca1 Unigram Precision} &= \\frac{17}{18}\\\\ \\text{Ca2 Unigram Precision} &= \\frac{8}{14}\\end{aligned}$$\n",
    "\n",
    "이제부터 단어라는 표현보다는 유니그램이라는 용어로 설명하겠습니다. 지금까지 설명한 유니그램 정밀도는 나름 의미있는 측정 방법으로 보이지만 사실 허술한 점이 있습니다. 아래와 같은 새로운 예가 있다고 해보겠습니다.\n",
    "<br /><br />\n",
    "\n",
    "### 중복을 제거하여 보정하기(Modified Unigram Precision)\n",
    "\n",
    "<br />\n",
    "\n",
    "- Candidate : the the the the the the the\n",
    "\n",
    "- Reference1 : the cat is on the mat\n",
    "\n",
    "- Reference2 : there is a cat on the mat\n",
    "\n",
    "<br />\n",
    "\n",
    "위의 Ca는 the만 7개가 등장한 터무니없는 번역입니다. 하지만 이 번역은 앞서 배운 유니그램 정밀도에 따르면 $\\frac{7}{7} = 1$이라는 최고의 성능 평가를 받게 됩니다. 따라서 유니그램 정밀도를 보정할 필요가 있습니다.\n",
    "<br />\n",
    "\n",
    "이를 보정하기 위해서는 정밀도의 분자를 계산하기 위해 Ref와 매칭하여 카운트하는 과정에서 Ca의 유니그램이 이미 Ref에서 매칭된 적이 있었는지를 고려해야 합니다.\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "$$\\text{Unigram Precision} = \\frac{\\text{Ref들과 Ca를 고려한 새로운 카운트 방법!!!}}{\\text{Ca의 총 유니그램 수}}$$\n",
    "\n",
    "<br />\n",
    "정밀도의 분자를 계산하기 위한 각 유니그램의 카운트는 다음과 같이 수정하겠습니다. \n",
    "<br />\n",
    "\n",
    "우선, 유니그램이 하나의 Ref에서 최대 몇 번 등장했는지 카운트합니다. 이 값을 maximum reference count(Max_Ref_Count)라고 부르겠습니다.\n",
    "<br />\n",
    "\n",
    "Max_Ref_Count가 기존의 단순 카운트한 값보다 작은 경우에는 이 값을 최종 카운트 값으로 대체합니다. 정밀도의 분자 계산을 위한 새로운 카운트 방식을 식으로 표현하면 아래와 같습니다.\n",
    "\n",
    "<br />\n",
    "\n",
    "$\\text{Count}\\_{\\text{clip}} = min(\\text{Count},\\; \\text{Max\\_Ref\\_Count})$\n",
    "\n",
    "<br />\n",
    "\n",
    "위의 카운트를 사용하여 분자를 계산한 정밀도를 **보정된 유니그램 정밀도(Modified Unigram Precision)**라고 합니다.\n",
    "\n",
    "<br />\n",
    "\n",
    "$$\\text{Modified Unigram Precision} = \\frac{\\text{Ca의 각 유니그램에 대해 \\text{Count}\\_{\\text{clip}} 을 수행한 값의 총 합}}{\\text{Ca의 총 유니그램 수}}$$\n",
    "\n",
    "<br />\n",
    "\n",
    "### 3) 보정된 유니그램 정밀도(Modified Unigram Precision) 구현하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "\n",
    "# tokens에서 n-gram 단순 카운트\n",
    "def simple_count(tokens, n):\n",
    "    return Counter(ngrams(tokens, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram count :  Counter({('the',): 3, ('It',): 1, ('is',): 1, ('a',): 1, ('guide',): 1, ('to',): 1, ('action',): 1, ('which',): 1, ('ensures',): 1, ('that',): 1, ('military',): 1, ('always',): 1, ('obeys',): 1, ('commands',): 1, ('of',): 1, ('party.',): 1})\n"
     ]
    }
   ],
   "source": [
    "# Candidate 1 \n",
    "candidate = \"It is a guide to action which ensures that the military always obeys the commands of the party.\"\n",
    "tokens = candidate.split()\n",
    "result = simple_count(tokens, 1) # n=1 유니그램\n",
    "print('Unigram count : ', result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram count :  Counter({('the',): 7})\n"
     ]
    }
   ],
   "source": [
    "# Candidate (Example 2)\n",
    "candidate = 'the the the the the the the'\n",
    "tokens = candidate.split()\n",
    "result = simple_count(tokens, 1)\n",
    "print('Unigram count : ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count_clip \n",
    "def count_clip(candidate, reference_list, n):\n",
    "    # Ca 문장에서 n-gram count\n",
    "    ca_cnt = simple_count(candidate, n)\n",
    "    max_ref_cnt_dict = dict()\n",
    "\n",
    "    for ref in reference_list:\n",
    "        # Ref 문장에서 n-gram count\n",
    "        ref_cnt = simple_count(ref, n)\n",
    "\n",
    "        # 각 Ref 문장에 대해 비교하여 n-gram의 최대 등장 횟수를 계산\n",
    "        for n_gram in ref_cnt:\n",
    "            if n_gram in max_ref_cnt_dict:\n",
    "                max_ref_cnt_dict[n_gram] = max(ref_cnt[n_gram], max_ref_cnt_dict[n_gram])\n",
    "            else:\n",
    "                max_ref_cnt_dict[n_gram] = ref_cnt[n_gram]\n",
    "    \n",
    "    return {\n",
    "        # count_clip = min(count, max_ref_count)\n",
    "        n_gram : min(ca_cnt.get(n_gram, 0), max_ref_cnt_dict.get(n_gram, 0)) for n_gram in ca_cnt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Unigram Count :  {('the',): 2}\n"
     ]
    }
   ],
   "source": [
    "candidate = 'the the the the the the the'\n",
    "references = [\n",
    "    'the cat is on the mat',\n",
    "    'there is a cat on the mat'\n",
    "]\n",
    "\n",
    "result = count_clip(candidate.split(), list(map(lambda ref: ref.split(), references)), 1)\n",
    "print('Modified Unigram Count : ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Unigram Precision :  0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "# Modified Unigram Precision\n",
    "def modified_precision(candidate, reference_list, n):\n",
    "    clip_cnt = count_clip(candidate, reference_list, n)\n",
    "    total_clip_cnt = sum(clip_cnt.values()) # 분자\n",
    "\n",
    "    cnt = simple_count(candidate, n)\n",
    "    total_cnt = sum(cnt.values()) # 분모\n",
    "\n",
    "    # 분모 != 0\n",
    "    if total_cnt == 0:\n",
    "        total_cnt = 1\n",
    "\n",
    "    # 분자 : count_clip의 합\n",
    "    # 분모 : 단순 count의 합\n",
    "    return (total_clip_cnt / total_cnt)\n",
    "\n",
    "result = modified_precision(candidate.split(), list(map(lambda ref: ref.split(), references)), 1)\n",
    "print('Modified Unigram Precision : ', result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 순서를 고려하기 위해서 n-gram으로 확장하기\n",
    "\n",
    "<br />\n",
    "\n",
    "BoW 표현과 유사하게, 유니그램 정밀도와 같이 각 단어의 빈도수로 접근하는 방법은 결국 단어의 순서를 고려하지 않는다는 특징이 있습니다.\n",
    "<br />\n",
    "\n",
    "Example 1에 Ca3라는 새로운 문장을 추가해보고 기존의 Ca1과 비교해보겠습니다.\n",
    "<br />\n",
    "\n",
    "- Candidate1 : It is a guide to action which ensures that the military always obeys the commands of the party.\n",
    "\n",
    "- Candidate2 : It is to insure the troops forever hearing the activity guidebook that party direct.\n",
    "\n",
    "- Candidate3 : the that military a is It guide ensures which to commands the of action obeys always party the.\n",
    "\n",
    "- Reference1 : It is a guide to action that ensures that the military will forever heed Party commands.\n",
    "\n",
    "- Reference2 : It is the guiding principle which guarantees the military forces always being under the command of the Party.\n",
    "\n",
    "- Reference3 : It is the practical guide for the army always to heed the directions of the party.\n",
    "\n",
    "<br />\n",
    "Ca3는 사실 Ca1에서 모든 유니그램의 순서를 랜덤으로 섞은 실제 영어 문법에 맞지 않는 문장입니다. 하지만 Ref 1, 2, 3과 비교하여 유니그램 정밀도를 적용하면 Ca1과 Ca3의 정밀도는 동일합니다. 유니그램 정밀도는 유니그램의 순서를 전혀 고려하지 않기 때문입니다.\n",
    "<br />\n",
    "\n",
    "이를 위한 대안으로 유니그램 왜에도 Bigram, Trigram, 4-gram 단위 등으로 계산한 정밀도. 즉, n-gram을 이용한 정밀도를 적용하고자 합니다.\n",
    "<br />\n",
    "\n",
    "이들 각각은 카운트 단위를 2개, 3개, 4개로 보느냐의 차이입니다. 어떤 의미인지 Bigram단위로 카운트하여 정밀도를 계산해보겠습니다.\n",
    "<br />\n",
    "\n",
    "- Candidate1 : the the the the the the the\n",
    "\n",
    "- Candidate2 : the cat the cat on the mat\n",
    "\n",
    "- Reference1 : the cat is on the mat\n",
    "\n",
    "- Reference2 : there is a cat on the mat\n",
    "<br />\n",
    "\n",
    "Ca2 바이그램의 Count와 $\\text{Count}_{\\text{clip}}$ 은 아래와 같습니다.\n",
    "<br />\n",
    "\n",
    "|바이그램|the cat|cat the|cat on|on the|the mat|SUM|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|Count|2|1|1|1|1|6|\n",
    "|$\\text{Count}_{\\text{clip}}$ |1|0|1|1|1|4|\n",
    "\n",
    "<br />\n",
    "결과적으로 Ca2의 바이그램 정밀도는 4/6가 됩니다. \n",
    "<br />\n",
    "\n",
    "이처럼 n-gram을 이용하여 보정된 정밀도를 계산하는 식을 작성해보면 아래와 같습니다.\n",
    "<br />\n",
    "\n",
    "$$p_n = \\frac{\\sum_{\\text{n-gram} \\in \\text{Candidate}} \\text{Count}_{\\text{clip}} (\\text{unigram})}{\\sum_{\\text{n-gram} \\in \\text{Candidate}} \\text{Count} (\\text{n-gram})}$$\n",
    "<br />\n",
    "\n",
    "n-gram 정밀도 식을 이해하였다면 BLEU의 최종 식까지 다 왔습니다. BLEU는 보정된 정밀도 $p_1,\\; p_2,\\; p_3,\\; \\ldots,\\; p_n$를 모두 조합하여 사용합니다. 이를 모두 조합한 BLEU의 식은 아래와 같습니다.\n",
    "<br />\n",
    "\n",
    "$$\\text{BLEU} = \\exp(\\sum_{n=1}^N w_n \\log p_n)$$\n",
    "<br />\n",
    "\n",
    "- $p_n$ : 각 n-gram의 보정된 정밀도입니다.\n",
    "\n",
    "- $N$ : n-gram에서 n의 최대 숫자입니다. 보통은 4를 가지고, $N$이 4라는 것은 $p_1,\\; p_2,\\; p_3,\\; p_4$를 사용한다는 것을 말합니다.\n",
    "\n",
    "- $w_n$ : 각 n-gram의 보정된 정밀도에서 서로 다른 가중치를 줄 수 있습니다. 이 가중치의 합은 1이 되도록 합니다.\n",
    "<br />\n",
    "\n",
    "### 5) 짧은 문장 길이에 대한 패널티(Brevity Penalty)\n",
    "<br />\n",
    "\n",
    "n-gram으로 단어의 순서를 고려한다고 하더라도 여전히 남아있는 문제가 있는데, 바로 Ca의 길이에 BLEU의 점수가 과한 영향을 받을 수 있다는 점입니다. \n",
    "<br />\n",
    "\n",
    "example 1에 다음의 Ca를 추가한다고 해보겠습니다.\n",
    "<br />\n",
    "\n",
    "- Candidate 4 : it is\n",
    "<br />\n",
    "\n",
    "이 문장은 유니그램 정밀도나 바이그램 정밀도가 각각 $\\frac{2}{2},\\; \\frac{1}{1}$로 두 정밀도 모두 1이라는 높은 정밀도는 얻습니다. 이와 같이 제대로 된 번역이 아님에도 문장의 길이가 짧다는 이유로 높은 점수를 받는 것은 이상합니다. 그래서 Ca가 Ref보다 문장의 길이가 짧은 경우에는 점수에 패널티를 줄 필요가 있습니다. 이를 브레버티 패너티(Brevity Penalty)라고 합니다. \n",
    "<br />\n",
    "\n",
    "이에 대해 살펴보기 전에, 만약 반대고 Ca의 길이가 Ref보다 긴 경우에도 문제가 생길 수 있는지 보겠습니다.\n",
    "<br />\n",
    "\n",
    "- Candidate 1: I always invariably perpetually do.\n",
    "\n",
    "- Candidate 2: I always do.\n",
    "\n",
    "- Reference 1: I always do.\n",
    "\n",
    "- Reference 2: I invariably do.\n",
    "\n",
    "- Reference 3: I perpetually do.\n",
    "<br />\n",
    "\n",
    "위 예시에서 Ca1은 가장 많은 단어를 사용했지만 Ca2보다 좋지 못한 번역입니다. 다시 말해 Ref의 단어를 가장 많이 사용한 것이 꼭 좋은 번역이라는 의미는 아닙니다. 하지만 다행히도 위와 같이 Ca의 길이가 불필요하게 Ref보다 긴 경우에는 BLEU 수식에서 정밀도를 n-gram으로 확장하여 바이그램, 트라이그램 정밀도 등을 모두 계산에 사용하고 있는 것만으로도 이미 패널티를 받고 있습니다. 즉, Brevity Penalty를 설계할 때 이 경우까지 고려할 필요는 없습니다.\n",
    "<br />\n",
    "\n",
    "다시 Ref보다 Ca의 길이가 짧을 경우에 패널티를 주는 Brevity Penalty의 이야기로 돌아와보겠습니다. Brevity Penalty는 앞서 배운 BLEU의 식에 곱하는 방식으로 사용합니다. Brevity Penalty를 BP라고 했을 때, 최종 BLEU식은 아래와 같습니다.\n",
    "<br />\n",
    "\n",
    "$$\\text{BLEU} = \\text{BP} \\times \\exp(\\sum_{n=1}^N w_n \\log p_n)$$\n",
    "<br />\n",
    "\n",
    "위 식은 패널티를 줄 필요가 없는 경우에는 BP의 값이 1이어야 함을 의미합니다. 이를 반영한 BP의 수식은 아래와 같습니다.\n",
    "<br />\n",
    "\n",
    "$$\\text{BP} = \\begin{cases} 1 & \\text{if}\\; c > r\\\\ e^{(1-r/c)} & \\text{if}\\; c \\leq r\\end{cases}$$\n",
    "<br />\n",
    "\n",
    "- $c$ : Candidate length\n",
    "\n",
    "- $r$ : Candidate와 가장 길이 차이가 적은 Reference의 길이\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BLEU 구현\n",
    "\n",
    "# Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수\n",
    "def closest_ref_length(candidate, reference_list):\n",
    "    ca_len = len(candidate)\n",
    "    ref_lens = (len(ref) for ref in reference_list)\n",
    "\n",
    "    closest_ref_length = min(ref_lens, key=lambda ref_len : (abs(ref_len - ca_len), ref_len))\n",
    "    return closest_ref_length\n",
    "\n",
    "# Brevity Penalty\n",
    "def brevity_penalty(candidate, reference_list):\n",
    "    ca_len = len(candidate)\n",
    "    ref_len = closest_ref_length(candidate, reference_list)\n",
    "\n",
    "    if ca_len > ref_len:\n",
    "        return 1\n",
    "    \n",
    "    # candidate가 비어있다면 BP = 0 -> BLEU = 0.0\n",
    "    elif ca_len == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.exp(1 - ref_len / ca_len)\n",
    "    \n",
    "# BLEU SCORE\n",
    "def bleu_score(candidate, reference_list, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    bp = brevity_penalty(candidate, reference_list)\n",
    "\n",
    "    p_n = [modified_precision(candidate, reference_list, n=n) for n, _ in enumerate(weights, start=1)]\n",
    "\n",
    "    # p1, p2, p3, ..., pn\n",
    "    score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n",
    "    return bp * np.exp(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NLTK를 사용한 BLEU 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실습 코드로 구현한 BLEU :  0.5045666840058485\n",
      "\n",
      "NLTK의 BLEU :  0.5045666840058485\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "references = [\n",
    "    'It is a guide to action that ensures that the military will forever heed Party commands',\n",
    "    'It is the guiding principle which guarantees the military forces always being under the command of the Party',\n",
    "    'It is the practical guide for the army always to heed the directions of the party'\n",
    "]\n",
    "\n",
    "print('실습 코드로 구현한 BLEU : ',bleu_score(candidate.split(), list(map(lambda ref : ref.split(), references))))\n",
    "print()\n",
    "print('NLTK의 BLEU : ', bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)), candidate.split()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의문점\n",
    "\n",
    "단순히 카운트 기반으로 점수를 측정하는데... 이러면 만약 의역이나 초월번역은 어떻게 점수를 측정할지가 궁금하다.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96512990021685504d4683198faad895f5cd0e4b7b1aa29365fef97d0a48eb34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
