{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentencePiece\n",
    "\n",
    "## 1. SentencePiece\n",
    "\n",
    "- 논문 : https://arxiv.org/pdf/1808.06226.pdf\n",
    "\n",
    "- 센텐스피스 깃허브 : https://github.com/google/sentencepiece\n",
    "\n",
    "구글은 BPE 알고리즘과 Unigram Language Model Tokenizer를 구현한 SentencePiece를 깃허브에 공개하였습니다.\n",
    "\n",
    "내부 단어 분리 알고리즘을 사용하기 위해서, 데이터에 단어 토큰화를 먼저 진행한 상태여야 한다면 이 단어 분리 알고리즘을 모든 언어에 사용하는 것은 쉽지 않습니다. 영어와 달리 한국어와 같은 언어는 토큰화부터 쉽지 않기 때문입니다. \n",
    "\n",
    "그런데, 이런 사전 토큰화 작업(pretokenization)없이 전처리를 하지 않은 데이터(raw data)에 바로 단어 분리 토크나이저를 사용할 수 있는 토크나이저가 SentencePiece입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IMDB 리뷰 토큰화로 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x14e405a0610>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import csv\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        My family and I normally do not watch local mo...\n",
       "1        Believe it or not, this was at one time the wo...\n",
       "2        After some internet surfing, I found the \"Home...\n",
       "3        One of the most unheralded great works of anim...\n",
       "4        It was the Sixties, and anyone with long hair ...\n",
       "                               ...                        \n",
       "49995    the people who came up with this are SICK AND ...\n",
       "49996    The script is so so laughable... this in turn,...\n",
       "49997    \"So there's this bride, you see, and she gets ...\n",
       "49998    Your mind will not be satisfied by this nobud...\n",
       "49999    The chaser's war on everything is a weekly sho...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('IMDb_Reviews.csv')\n",
    "train_df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentencepiece의 입력으로 사용하기 위해 txt파일로 저장\n",
    "with open('imdb_reveiw.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(train_df['review']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input : 학습시킬 파일\n",
    "\n",
    "- model_prefix : 만들어질 모델 이름\n",
    "\n",
    "- vocab_size : 단어 집합의 크기\n",
    "\n",
    "- model_type : 사용할 모델 (unigram(default), bpe, char, word)\n",
    "\n",
    "- max_sentence_length: 문장의 최대 길이\n",
    "\n",
    "- pad_id, pad_piece: pad token id, 값\n",
    "\n",
    "- unk_id, unk_piece: unknown token id, 값\n",
    "\n",
    "- bos_id, bos_piece: begin of sentence token id, 값\n",
    "\n",
    "- eos_id, eos_piece: end of sequence token id, 값\n",
    "\n",
    "- user_defined_symbols: 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=imdb_reveiw.txt --model_prefix=imdb --vocab_size=30000 --model_type=bpe --max_sentence_length=9999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>▁Ste</td>\n",
       "      <td>-1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29752</th>\n",
       "      <td>▁Phel</td>\n",
       "      <td>-29749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>TER</td>\n",
       "      <td>-6877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13922</th>\n",
       "      <td>phia</td>\n",
       "      <td>-13919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25324</th>\n",
       "      <td>imps</td>\n",
       "      <td>-25321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22853</th>\n",
       "      <td>Win</td>\n",
       "      <td>-22850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>▁teen</td>\n",
       "      <td>-1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22718</th>\n",
       "      <td>▁Shaggy</td>\n",
       "      <td>-22715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19831</th>\n",
       "      <td>Son</td>\n",
       "      <td>-19828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>ween</td>\n",
       "      <td>-746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1\n",
       "1208      ▁Ste  -1205\n",
       "29752    ▁Phel -29749\n",
       "6880       TER  -6877\n",
       "13922     phia -13919\n",
       "25324     imps -25321\n",
       "22853      Win -22850\n",
       "1651     ▁teen  -1648\n",
       "22718  ▁Shaggy -22715\n",
       "19831      Son -19828\n",
       "749       ween   -746"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .vocab 파일에 학습된 단어들 저장\n",
    "vocab_list = pd.read_csv('imdb.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 파일을 로드하여 인코딩, 디코딩 작업 가능\n",
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"imdb.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- encode_as_pieces : 문장을 입력하면 서브 워드 시퀀스로 변환\n",
    "\n",
    "- encode_as_idx : 문장을 입력하면 정수 시퀀스로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't at all think of it this way.\n",
      "['▁I', '▁didn', \"'\", 't', '▁at', '▁all', '▁think', '▁of', '▁it', '▁this', '▁way', '.']\n",
      "[41, 623, 29950, 29926, 138, 169, 378, 30, 58, 73, 413, 29945]\n",
      "\n",
      "I have waited a long time for someone to film\n",
      "['▁I', '▁have', '▁waited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
      "[41, 141, 9795, 4, 666, 285, 92, 1078, 33, 91]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "    \"I didn't at all think of it this way.\",\n",
    "    \"I have waited a long time for someone to film\"\n",
    "]\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    print(sp.encode_as_pieces(line))\n",
    "    print(sp.encode_as_ids(line))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 집합의 크기 확인\n",
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁character'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정수 -> 단어\n",
    "sp.IdToPiece(430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 -> 정수\n",
    "sp.PieceToId('▁character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have waited a long time for someone to film'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정수 시퀀스 -> 문장\n",
    "sp.DecodeIds([41, 141, 1364, 1120, 4, 666, 285, 92, 1078, 33, 91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have waited a long time for someone to film'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 시퀀스 -> 문장\n",
    "sp.DecodePieces(['▁I', '▁have', '▁waited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁have', '▁waited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
      "[41, 141, 9795, 4, 666, 285, 92, 1078, 33, 91]\n"
     ]
    }
   ],
   "source": [
    "# encode\n",
    "# out_type = str : 문장 -> pieces\n",
    "# out_type = int : 문장 -> 정수 시퀀스\n",
    "print(sp.encode('I have waited a long time for someone to film', out_type=str))\n",
    "print(sp.encode('I have waited a long time for someone to film', out_type=int))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 리뷰 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import csv\n",
    "\n",
    "data_path = 'C:/Users/Myeong/dding/data/딥러닝-자연어처리입문/ratings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_df = pd.read_table(data_path)\n",
    "naver_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_df = naver_df.dropna(how='any')\n",
    "naver_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199992"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(naver_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(naver_df['document']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=naver_review.txt --model_prefix=naver --vocab_size=32000 --model_type=bpe --max_sentence_length=9999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>영화</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁이</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁아</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>▁그</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  <unk>  0\n",
       "1    <s>  0\n",
       "2   </s>  0\n",
       "3     ..  0\n",
       "4     영화 -1\n",
       "5    ▁영화 -2\n",
       "6     ▁이 -3\n",
       "7     ▁아 -4\n",
       "8    ... -5\n",
       "9     ▁그 -6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv('naver.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = 'naver.model'\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뭐 이딴 것도 영화냐.\n",
      "[132, 966, 1296, 2590, 30276]\n",
      "['▁뭐', '▁이딴', '▁것도', '▁영화냐', '.']\n",
      "\n",
      "진짜 최고의 영화입니다 ㅋㅋ\n",
      "[54, 200, 821, 85]\n",
      "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[\n",
    "    '뭐 이딴 것도 영화냐.',\n",
    "    '진짜 최고의 영화입니다 ㅋㅋ'\n",
    "]\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    print(sp.EncodeAsIds(line))\n",
    "    print(sp.EncodeAsPieces(line))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
      "[54, 200, 821, 85]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode(lines[1], out_type=str))\n",
    "print(sp.encode(lines[1], out_type=int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96512990021685504d4683198faad895f5cd0e4b7b1aa29365fef97d0a48eb34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
